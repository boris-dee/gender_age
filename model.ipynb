{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9a9066",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    BatchNormalization,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    Dense,\n",
    "    ReLU,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfa353",
   "metadata": {},
   "source": [
    "# GPU Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e75af3f",
   "metadata": {},
   "source": [
    "# File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e165b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the FairFace dataset\n",
    "\n",
    "train_file = '../databases/fairface/fairface_label_train.csv'\n",
    "val_file = '../databases/fairface/fairface_label_val.csv'\n",
    "img_root = '../databases/fairface/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c0144",
   "metadata": {},
   "source": [
    "# Other Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5778e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop from the train and validation dataframes\n",
    "cols_to_drop = ['service_test', 'race']\n",
    "\n",
    "# Define target labels: 'age', 'gender'\n",
    "target_label = ['gender', 'age']\n",
    "\n",
    "# Image size for the conv net\n",
    "img_size = 64\n",
    "\n",
    "# Batch size for the conv net\n",
    "batch_size = 64\n",
    "\n",
    "# Learning rate of the model\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Maximum number of epochs\n",
    "nepochs = 5\n",
    "\n",
    "# Print training information every display_epoch epochs\n",
    "display_epoch = 1\n",
    "\n",
    "# Age labels : for better predictions, we create age groups \n",
    "age_labels = ['0-19', '20-29', '30-39', '40-49', '50+']\n",
    "\n",
    "# Number of age classes used for the loss calculation\n",
    "n_age_classes = len(age_labels)\n",
    "ps_n_age_classes = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff404e",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the age distribution as an histogram\n",
    "def plot_age(df):\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.hist(df.age, bins=range(n_age_classes + 1), align='left', rwidth=0.5, density=True)\n",
    "    ax.set_title('Age Classes', fontdict = {'fontsize': 40})\n",
    "    ax.set_xlabel('Age classes', fontdict = {'fontsize': 20})\n",
    "    ax.set_xticks(np.arange(0,n_age_classes,1))\n",
    "\n",
    "    ax.set_ylabel('Proportion', fontdict = {'fontsize': 20})\n",
    "    ax.set_xticklabels(age_labels, fontdict = {'fontsize': 15})\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607637f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframes from csv files\n",
    "raw_train_df = pd.read_csv(train_file)\n",
    "raw_val_df = pd.read_csv(val_file)\n",
    "\n",
    "# Number of training and validation examples before filters\n",
    "ntrain = raw_train_df.shape[0]\n",
    "nval = raw_val_df.shape[0]\n",
    "\n",
    "# Apply filters to the dataframes and transform categorical age to numerical\n",
    "for df in [raw_train_df, raw_val_df]:\n",
    "    # Drop useless columns\n",
    "    for col in cols_to_drop:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "    # Add root to the file path\n",
    "    df.file = df.file.apply(lambda x: img_root + x)\n",
    "    \n",
    "    df.gender = df.gender.replace({'Male': 1, 'Female': 0}).astype(int)\n",
    "\n",
    "    df.age = df.age.replace({'0-2': 0, '3-9': 0, '10-19': 0, \n",
    "                             '20-29': 1, '30-39': 2, '40-49': 3, \n",
    "                             '50-59': 4, '60-69': 4, 'more than 70': 4}).astype(int)\n",
    "    \n",
    "# Number of training and validation examples before filters\n",
    "ntrain = raw_train_df.shape[0]\n",
    "nval = raw_val_df.shape[0]\n",
    "\n",
    "print('Number of training examples: %i.' %ntrain)\n",
    "print('Number of validation examples: %i.' %nval)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Get the number of training and validation batches\n",
    "n_train_batches = int(np.ceil(raw_train_df.shape[0] / batch_size))\n",
    "n_val_batches = int(np.ceil(raw_val_df.shape[0] / batch_size))\n",
    "\n",
    "print('Number of batches in training set: %i.' %n_train_batches)\n",
    "print('Number of batches in validation set: %i.' %n_val_batches)\n",
    "print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_age(raw_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10669d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "max_size = raw_train_df['age'].value_counts().max()\n",
    "\n",
    "lst = [raw_train_df]\n",
    "for class_index, group in raw_train_df.groupby('age'):\n",
    "    lst.append(group.sample(max_size - len(group), replace=True))\n",
    "raw_train_df = pd.concat(lst)\n",
    "\n",
    "plot_age(raw_train_df)\n",
    "\n",
    "# Get the new number of training batches\n",
    "n_train_batches = int(np.ceil(raw_train_df.shape[0] / batch_size))\n",
    "\n",
    "print('Number of batches in training set: %i.' %n_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderAgeEstimator(Model):\n",
    "    def __init__(self):\n",
    "        super(GenderAgeEstimator, self).__init__()        \n",
    "        self.conv1 = Conv2D(filters=64, kernel_size=3, name=\"Conv_1\")\n",
    "        self.maxpool1 = MaxPool2D(strides=2, name=\"MaxPool_1\")\n",
    "        self.bn1 = BatchNormalization(name=\"BatchNorm_1\")\n",
    "        self.relu1 = ReLU(name=\"Relu_1\")\n",
    "\n",
    "        self.conv2 = Conv2D(filters=128, kernel_size=3, name=\"Conv_2\")\n",
    "        self.maxpool2 = MaxPool2D(strides=2, name=\"MaxPool_2\")\n",
    "        self.bn2 = BatchNormalization(name=\"BatchNorm_2\")\n",
    "        self.relu2 = ReLU(name=\"Relu_2\")\n",
    "\n",
    "        self.conv3 = Conv2D(filters=256, kernel_size=3, name=\"Conv_3\")\n",
    "        self.maxpool3 = MaxPool2D(strides=2, name=\"MaxPool_3\")\n",
    "        self.bn3 = BatchNormalization(name=\"BatchNorm_3\")\n",
    "        self.relu3 = ReLU(name=\"Relu_3\")\n",
    "\n",
    "        self.conv4 = Conv2D(filters=512, kernel_size=3, name=\"Conv_4\")\n",
    "        self.maxpool4 = MaxPool2D(strides=2, name=\"MaxPool_4\")\n",
    "        self.bn4 = BatchNormalization(name=\"BatchNorm_4\")\n",
    "        self.relu4 = ReLU(name=\"Relu_4\")\n",
    "\n",
    "        self.flatten = Flatten(name=\"Flatten\")\n",
    "        self.dropout = Dropout(rate=0.4, name=\"Dropout\")\n",
    "\n",
    "        self.fc1 = Dense(units=1024, name=\"Dense\")\n",
    "        self.bn5 = layers.BatchNormalization(name=\"BatchNorm_5\")\n",
    "\n",
    "        self.out_gender = layers.Dense(units=2, name=\"Gender\")\n",
    "        self.out_age = layers.Dense(ps_n_age_classes, name=\"Age\")\n",
    "\n",
    "        self.call(Input(shape=(img_size,img_size,3)))\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.bn1(x, training=is_training)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.bn2(x, training=is_training)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.bn3(x, training=is_training)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.bn4(x, training=is_training)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x, training=is_training)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn5(x, training=is_training)\n",
    "\n",
    "        # Output for gender\n",
    "        x_gender = self.out_gender(x)\n",
    "        if not is_training:\n",
    "            x_gender = tf.nn.softmax(x_gender)\n",
    "        \n",
    "        # Output for age\n",
    "        x_age = self.out_age(x)\n",
    "        if not is_training:\n",
    "            x_age = tf.nn.softmax(x_age)\n",
    "        \n",
    "        return (x_gender, x_age)\n",
    "\n",
    "    def summary(self):\n",
    "        x = Input(shape=(img_size, img_size, 3), name='Input')\n",
    "        return Model(inputs=x, outputs=self.call(x), name='GenderAgeEstimator').summary()\n",
    "\n",
    "# Build model.\n",
    "model = GenderAgeEstimator()\n",
    "print(model.summary())\n",
    "\n",
    "# Load pretrained weights\n",
    "model.load_weights('save/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396868e0",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa34061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the predictions mean and rescale it back to the number of age classes\n",
    "def scaled_mean(y_pred_age):\n",
    "    mean = tf.reduce_sum(y_pred_age * tf.cast(tf.range(0, ps_n_age_classes, 1), tf.float32), axis=1)\n",
    "    \n",
    "    scaled_mean = tf.transpose(mean / ps_n_age_classes * n_age_classes)\n",
    "    \n",
    "    return scaled_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint loss\n",
    "def joint_loss(y_pred_gender, y_pred_age, y_true):\n",
    "    # Extract target labels\n",
    "    gt_gender = y_true[:, 0]    \n",
    "    gt_age = y_true[:, 1]\n",
    "            \n",
    "    # Loss for gender: cross-entropy\n",
    "    gt_gender = tf.cast(gt_gender, tf.int64)\n",
    "    loss_gender = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=gt_gender, logits=y_pred_gender)\n",
    "    loss_gender = tf.reduce_mean(loss_gender)\n",
    "    \n",
    "    # Loss for age: scaled MAE\n",
    "    gt_age = tf.cast(gt_age, tf.float32)\n",
    "    \n",
    "    scaled_age_preds = scaled_mean(y_pred_age)\n",
    "    \n",
    "    loss_age = tf.keras.losses.mean_absolute_error(scaled_age_preds, gt_age)\n",
    "    \n",
    "    return loss_gender + loss_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7d1d8",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea27e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(x, y_true):\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass\n",
    "        y_pred_gender, y_pred_age = model(x, is_training=True)\n",
    "                \n",
    "        # Compute joint loss\n",
    "        loss = joint_loss(y_pred_gender, y_pred_age, y_true)\n",
    "        \n",
    "    # Trainable variables.\n",
    "    trainable_variables = model.trainable_variables\n",
    "\n",
    "    # Compute gradients\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6715945c",
   "metadata": {},
   "source": [
    "# Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_gender(y_pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, axis=1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "def accuracy_age(y_pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.round(y_pred, tf.float32), tf.cast(y_true, tf.float32))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90b568",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3474ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for processing batch images\n",
    "def process_image(img_path, is_training=False):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.\n",
    "    img = cv2.resize(img, (img_size, img_size), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    if is_training and random.random() < 0.5:\n",
    "        # Flip horizontally\n",
    "        img = cv2.flip(img, 1)\n",
    "        \n",
    "        # Motion blur\n",
    "        size = np.random.randint(1,18)\n",
    "        kernel_motion_blur = np.zeros((size, size))\n",
    "        kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "        kernel_motion_blur = kernel_motion_blur / size\n",
    "        img = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec582ffb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Average time taken by an epoch\n",
    "average_time_epoch = 0\n",
    "\n",
    "# Create validation batches\n",
    "val_batches = np.array_split(raw_val_df, n_val_batches)\n",
    "\n",
    "for epoch in range (1, nepochs + 1):\n",
    "    # Initialize timings\n",
    "    start_time_epoch = time.time()\n",
    "    time_epoch = 0\n",
    "\n",
    "    # Initialize accuracies\n",
    "    total_train_acc_gender = 0\n",
    "    total_train_acc_age = 0\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    total_val_acc_gender = 0\n",
    "    total_val_acc_age = 0\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    start_time_batch = time.time()\n",
    "    \n",
    "    # Create training batches: shuffle and split\n",
    "    raw_train_df = raw_train_df.sample(frac=1)\n",
    "    train_batches = np.array_split(raw_train_df, n_train_batches)\n",
    "    \n",
    "    # Loop over batches\n",
    "    for idx, batch in enumerate(train_batches, 1):\n",
    "        # Get ground truths\n",
    "        batch_y = batch[['gender', 'age']].values\n",
    "        \n",
    "        # Get image paths and process batch images\n",
    "        batch_x = batch['file'].apply(process_image, args=(True,))\n",
    "        batch_x = np.stack(batch_x.values).astype('float32')\n",
    "        \n",
    "        # Run the optimization to update W and b values.\n",
    "        run_optimization(batch_x, batch_y)\n",
    "        \n",
    "        # Calculate training loss/accuracy for this batch\n",
    "        train_pred_gender, train_pred_age = model(batch_x)        \n",
    "        train_loss = joint_loss(train_pred_gender, train_pred_age, batch_y)\n",
    "        train_acc_gender = accuracy_gender(train_pred_gender, batch_y[:,0])\n",
    "        train_acc_age = accuracy_age(scaled_mean(train_pred_age), batch_y[:,1])\n",
    "        \n",
    "        # Aggregate\n",
    "        total_train_acc_gender += train_acc_gender\n",
    "        total_train_acc_age += train_acc_age\n",
    "        total_train_loss += train_loss\n",
    "        \n",
    "    # Calculate mean\n",
    "    total_train_acc_gender = total_train_acc_gender / n_train_batches\n",
    "    total_train_acc_age = total_train_acc_age / n_train_batches\n",
    "    total_train_loss = total_train_loss / n_train_batches\n",
    "        \n",
    "    # Calculate validation loss/accuracy\n",
    "    start_time_batch = time.time()\n",
    "    \n",
    "    for idx, batch in enumerate(val_batches, 1):\n",
    "        # Get ground truths\n",
    "        batch_y = batch[['gender', 'age']].values\n",
    "        \n",
    "        # Get image paths and process batch images\n",
    "        batch_x = batch['file'].apply(process_image)\n",
    "        batch_x = np.stack(batch_x.values).astype('float32')\n",
    "        \n",
    "        val_pred_gender, val_pred_age = model(batch_x)\n",
    "        val_loss = joint_loss(val_pred_gender, val_pred_age, batch_y)\n",
    "        val_acc_gender = accuracy_gender(val_pred_gender, batch_y[:,0])\n",
    "        val_acc_age = accuracy_age(scaled_mean(val_pred_age), batch_y[:,1])\n",
    "\n",
    "        # Aggregate\n",
    "        total_val_acc_gender += val_acc_gender\n",
    "        total_val_acc_age += val_acc_age\n",
    "        total_val_loss += val_loss\n",
    "        \n",
    "        # Append all ground truths and preds\n",
    "        if idx == 1:\n",
    "            all_true_gender = batch_y[:, 0]\n",
    "            all_true_age = batch_y[:, 1]\n",
    "            all_file_names = batch['file'].values\n",
    "            \n",
    "            all_pred_gender = tf.argmax(val_pred_gender, axis=1).numpy()\n",
    "            all_pred_age = tf.round(scaled_mean(val_pred_age), tf.float32).numpy()\n",
    "        \n",
    "        else:\n",
    "            all_true_gender = np.append(all_true_gender, batch_y[:, 0])\n",
    "            all_true_age = np.append(all_true_age, batch_y[:, 1])\n",
    "            all_file_names = np.append(all_file_names, batch['file'].values)\n",
    "            \n",
    "            all_pred_gender = np.append(all_pred_gender, tf.argmax(val_pred_gender, axis=1).numpy())\n",
    "            all_pred_age = np.append(all_pred_age, tf.round(scaled_mean(val_pred_age), tf.float32).numpy())\n",
    "\n",
    "    # Calculate mean\n",
    "    total_val_acc_gender = total_val_acc_gender / n_val_batches\n",
    "    total_val_acc_age = total_val_acc_age / n_val_batches\n",
    "    total_val_loss = total_val_loss / n_val_batches\n",
    "        \n",
    "    # Keep track of single epoch time\n",
    "    time_epoch = time.time() - start_time_epoch\n",
    "           \n",
    "    # Aggregate time\n",
    "    average_time_epoch += time_epoch\n",
    "    \n",
    "    # Summary\n",
    "    if epoch % display_epoch == 0:\n",
    "        print('Epoch %3i |' %epoch, end=' ')\n",
    "        print('train loss: %0.5f | val loss: %0.5f | time: %0.2f sec.' %(total_train_loss, total_val_loss, time_epoch))\n",
    "        print('Gender    | train acc : %0.5f | val acc : %0.5f.' %(total_train_acc_gender, total_val_acc_gender))\n",
    "        print('Age       | train acc : %0.5f | val acc : %0.5f.' %(total_train_acc_age, total_val_acc_age))\n",
    "        print('=======================================================================')\n",
    "        \n",
    "# Calculate and print average time per epoch\n",
    "average_time_epoch = average_time_epoch / nepochs\n",
    "print('Average time per epoch: %0.2f sec.' %average_time_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation set predictions\n",
    "df = pd.DataFrame()\n",
    "df['file'] = all_file_names\n",
    "df['age_true'] = all_true_age\n",
    "df['age_pred'] = all_pred_age\n",
    "df['gender_true'] = all_true_gender\n",
    "df['gender_pred'] = all_pred_gender\n",
    "\n",
    "df.to_csv('FairFace_validation_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7bae1",
   "metadata": {},
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender confusion matrix\n",
    "cm_gender = tf.math.confusion_matrix(all_true_gender, all_pred_gender).numpy()\n",
    "\n",
    "# Age confusion matrice\n",
    "cm_age = tf.math.confusion_matrix(all_true_age, all_pred_age).numpy()\n",
    "\n",
    "# Calculate total number of people in each gender/age category\n",
    "gender_counts = cm_gender.sum(axis=1)\n",
    "age_counts = cm_age.sum(axis=1)\n",
    "\n",
    "# Calculate rates\n",
    "gender_rates = np.zeros(2)\n",
    "age_rates = np.zeros(n_age_classes)\n",
    "\n",
    "print('=====================================')\n",
    "print('============== Summary ==============')\n",
    "print('=====================================')\n",
    "for idx, gender in enumerate(['females', 'males']):\n",
    "    gender_rates[idx] = cm_gender[idx,idx]/gender_counts[idx]*100\n",
    "    print('Total number of %s is %i.' %(gender, gender_counts[idx]))\n",
    "    print('Prediction rate of %s is %0.2f%%.' %(gender, gender_rates[idx]))\n",
    "    print('')\n",
    "    \n",
    "print('        =====================        ')\n",
    "    \n",
    "for idx, age in enumerate(age_labels):\n",
    "    age_rates[idx] = cm_age[idx,idx]/age_counts[idx]*100\n",
    "    print('Total number of %s is %i.' %(age, age_counts[idx]))\n",
    "    print('Prediction rate of %s is %0.2f%%.' %(age, age_rates[idx]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ec44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some dictionnaries for confusion matrices\n",
    "fontdict_rates_gender = {'fontsize': 15, 'color': 'yellow'}\n",
    "fontdict_rates_age = {'fontsize': 13, 'color': 'yellow'}\n",
    "\n",
    "# Plot confusion matrices\n",
    "# Gender\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_title('Gender', fontdict = {'fontsize': 40})\n",
    "ax1 = sns.heatmap(cm_gender, annot=True, fmt=\"d\", linewidths=.5, cmap='coolwarm')\n",
    "\n",
    "ax1.set_xlabel('Predicted', fontdict = {'fontsize': 20})\n",
    "ax1.set_xticklabels(['Females', 'Males'], fontdict = {'fontsize': 15})\n",
    "\n",
    "ax1.set_ylabel('True', fontdict = {'fontsize': 20})\n",
    "ax1.set_ylim(2,0)\n",
    "ax1.set_yticklabels(['Females', 'Males'], fontdict = {'fontsize': 15})\n",
    "\n",
    "for idx, gender in enumerate(['female', 'male']):    \n",
    "    ax1.text(x=idx+0.35, y=idx+0.65, s='{:.2f}%'.format(gender_rates[idx]), fontdict = fontdict_rates_gender)\n",
    "\n",
    "# Age\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_title('Age', fontdict = {'fontsize': 40})\n",
    "ax2 = sns.heatmap(cm_age, annot=True, fmt=\"d\", linewidths=.5, cmap='coolwarm')\n",
    "\n",
    "ax2.set_xlabel('Predicted', fontdict = {'fontsize': 20})\n",
    "ax2.set_xticklabels(age_labels, fontdict = {'fontsize': 15})\n",
    "\n",
    "ax2.set_ylabel('True', fontdict = {'fontsize': 20})\n",
    "ax2.set_ylim(n_age_classes,0)\n",
    "ax2.set_yticklabels(age_labels, fontdict = {'fontsize': 15})\n",
    "\n",
    "for idx, age in enumerate(age_labels):\n",
    "    ax2.text(x=idx+0.2, y=idx+0.8, s='{:.2f}%'.format(age_rates[idx]), fontdict = fontdict_rates_age)\n",
    "    \n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a2654",
   "metadata": {},
   "source": [
    "# Save Weights\n",
    "To change ownership: `sudo chown user -R save`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44818069",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'save'\n",
    "save_file = save_dir + '/model'\n",
    "\n",
    "# Remove folder if it already exists\n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "model.save_weights(save_file)\n",
    "print('Weights saved to: %s.' %save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
